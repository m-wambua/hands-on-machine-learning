{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist=fetch_openml('mnist_784',version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data sets loaded by scikit learn generally have a similar dictionary structure\n",
    "# including:\n",
    "# aDESCR key describing the data set#\n",
    "# A data key containing an array with one row per instance and one column per feature\n",
    "# A target key containing an array with the labels#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=mnist[\"data\"],mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#There are 70,000 images each  image has 784 features.This is because each image is\n",
    "# 28X28 pixels and each feature simply represents one pixel's intensity from 0 (white)\n",
    "# to black(255). For one to view an image you need to grab an instance of a vector,reshape\n",
    "# it to 28X28 array and dispaly it using Matplotlib's imshow() function:\n",
    "# \n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=X.values\n",
    "t=s[0].reshape(28,28)\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "some_digit=X.values## i solved my first problem !!\n",
    "some_digit_image=some_digit[0].reshape(28, 28)\n",
    "\n",
    "plt.imshow(some_digit_image,cmap=mpl.cm.binary,interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now renaming as the label as an integer#\n",
    "import numpy as np\n",
    "y=y.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mnist data set is actually split into a training set(the first 60,000)\n",
    "# and a test set(the last 10,000)#\n",
    "X_train,X_test,y_train,y_test=X[:60000],X[60000:],y[:60000],y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The training set is already shuffled ,which is good as  this guarantees that all\n",
    "# cross-validation folds will be similar #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training  a binary classifier#\n",
    "#If we simplify the problem say to search for only one digit then the algorithm\n",
    "# becomes a binary detector#\n",
    "\n",
    "y_train_5=(y_train==5)#True for all 5s ,False for all other digits\n",
    "\n",
    "y_test_5=(y_test==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Picking up a classifier and training it.\n",
    "# A good place to start is with a Stochastic Gradient Descent(SGD) classifier\n",
    "# using scikit learn SGDClassifier class.This class has the advantage of being capable\n",
    "# of handling large datasets effiecently#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "sgd_clf=SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train,y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.predict([some_digit[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance Measure #\n",
    "#Evaluating a classifier is often significantly trickier than evaaluating a regressor\n",
    "# #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measuring Accuracy using Cross-validation\n",
    "# \n",
    "# Implementing cross validation.Occasionally you will need more control over the\n",
    "#  cross validation process than what scikit-learn provides off the shelf. In these\n",
    "# cases,you can implement crossvalidation yourself and it is actually fairly straight forward.The\n",
    "# following cde  does roughly the same thing as scikit learn's cross_val_score() function\n",
    "# #\n",
    "\"\"\"from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds=StratifiedKFold(n_splits=3,random_state=42)\n",
    "\n",
    "for train_index,test_index in skfolds.split(X_train,y_train_5):\n",
    "    clone_clf=clone(sgd_clf)\n",
    "    X_train_folds=X_train[train_index]\n",
    "    y_train_folds=y_train_5[train_index]\n",
    "    X_test_fold=X_train[test_index]\n",
    "    y_test_fold=y_train_5[test_index]\n",
    "\n",
    "    clone_clf.fit(X_train_folds,y_train_folds)\n",
    "    y_pred=clone_clf.predict(X_test_fold)\n",
    "    n_correct=sum(y_pred==y_test_fold)\n",
    "\n",
    "    print(n_correct/len(y_pred))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf,X_train,y_train,cv=3,scoring=\"accuracy\")\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "class NeverSClassifier(BaseEstimator):\n",
    "    def fit (self,X,y=None):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf=NeverSClassifier()\n",
    "cross_val_score(never_5_clf,X_train,y_train_5,cv=3,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This means that  with over 90% accuracy you can guess an image is not a 5#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A much better way to evaluate the performance of a classifier is to look at \n",
    "# the confusion matrix.The general idea is to count the number of times instances\n",
    "# of class A are classified  as class B.To compute the confusion matrix ,you first\n",
    "#  need to have a set of predictions, so they can be compared to the actual targets.\n",
    "# You could  make predictions on the test set . Instead  , you can use the cross_val_predict()\n",
    "# function:#\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_train_pred=cross_val_predict(sgd_clf,X_train,y_train_5,cv=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just like the cross_val_score() function,cross_val_predict() performs\n",
    "# K-fold cross validation, but instead of returning the evaluation scores,\n",
    "# it returns the predictions made on each test fold.This ,means that you get a clean\n",
    "# prediction for each training instance in the training set.(Clean means that the \n",
    "# prediction is made by a model that never saw the data during training)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each row in a confusion matrix represents an actual class while each column \n",
    "# represents a predicted class.The first row of this matrix considers non-5 images\n",
    "# (the negative class): 53892 of them were correctly classified as non-5s (true negative)\n",
    "# while the remaining 687 of them were wrongly classified as 5s (false postives).\n",
    "# A second row considers the images of the 5s (the positive class): 1891 were wrongly\n",
    "# classified as non-5s(false negative), while the remaining 3530 were correctly clasified\n",
    "# as 5s(true positives).A perfect classifier would have only true positves and true \n",
    "# negatives, so its confusion matrix would have nonzero values only on its main\n",
    "# diagonal#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_perfect_predictions=y_train_5\n",
    "confusion_matrix(y_train_5,y_train_perfect_predictions)\n",
    "#Pretend we reached a perfection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The confusion matrix give you a lot of information ,but sometimes you may prefer\n",
    "# a more concise metric.An interesting one to look at is the accuracy of the positive \n",
    "# predictions; this is called the precision of the classifier#\n",
    "\n",
    "#precision= TP\n",
    "#         ---------\n",
    "#           TP + FP\n",
    "# TP=true positive\n",
    "# FP=false positive\n",
    "# A trivial way to have a perfect precision is ti make one single positive prediction\n",
    "#  and ensure it is correct.this would not be very useful since the clasifier would ignore\n",
    "#  all but one positive instance.So precision is usually used with another metric called\n",
    "# recall, also called sensitivity or true positive rate#\n",
    "\n",
    "#recall= TP\n",
    "#       ------\n",
    "#       TP+FN#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precion and Recall#\n",
    "\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "precision_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What this signifies is that when it claims an image it claims it correctly only\n",
    "# 83.70879772350012 % of the time and can only detect 65.11713705958311% of the 5s#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is often convinient to combine precision and recall into a single metric called\n",
    "#  the F1 score , in particular if you need a simple way to compare two classifiers.The \n",
    "# F1 score is the harmonic mean of precision and recall.Whereas the regualr mean treats\n",
    "# asll values as equal , the harmonic mean gives much more weight to low values.\n",
    "# As a result, the classifier will only get a high F1,score if both recall precision\n",
    "#  are high#\n",
    "\n",
    "#\n",
    "    # F1=       2\n",
    "    #   --------------------------------------\n",
    "    #       1                          1\n",
    "    #    ---------------     + ---------------\n",
    "    #       precision                recall\n",
    "    # \n",
    "    # \n",
    "    # #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_train_5,y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The F1 classifiers favours classifiers that have similar precision and recall.This \n",
    "# is not always what you want: in some context you mostly  care about precision, and\n",
    "# in other contexts you really care about recall.For example ,if you trained a classifier\n",
    "# to detect videos that are safe for kids , you would probably prefer a classifier\n",
    "# that rejects many good videos(low recall) but keeps only safe ones (high precision),\n",
    "# rather than a classifier  that has a much higher recall but lets a few  really bad\n",
    "#  videos show up in your product.On the other hand,suppose you train a classifier to detect\n",
    "# shoplifters on surveillance images: it is probably fine if your classifier has only \n",
    "# 30% precision as long as it has 99% recall.\n",
    "# \n",
    "# Unfortunately ,you can't have it both ways: increasing precision reduces recall, and\n",
    "# vice versa.This is called the precision/recall tradeoff#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision/Recall Tradeoff\n",
    "# To understand the tradeoff , let's look at how the SGDClassifier makes its\n",
    "# classification decisions. For Each instance,it computes a score based on\n",
    "#  a decion funtion and if it score is greater than a threshold ,it assigns\n",
    "# the instance to the positive class, or else it assigns it to the negative class.\n",
    "# Suppose the decison threshold is positioned at the central arrow : you will find\n",
    "# 4 true positives and(actual 5s ) and on the right of that threshold,and one false \n",
    "# positive(actual 6 ).Therefore,with that threshold ,the precision is 80%.But out of\n",
    "# 6 actual 5s , the clasifier only detects 4,so the recall is 67%.Now if you raised\n",
    "#  the threshold,the false positive  becomes a true negative,thereby increasing \n",
    "# precision but one true positive becomes a false negative,decreasing recall down to\n",
    "# 50% .Conversely,lowering the threshold increasing recall and reduces precision. #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit learn does not let you set the threshold directly,but it does give you access\n",
    "# to the decision scores that it uses to make predictions.instead of calling the classifier\n",
    "# predict()  method,you can call its decisions_function() method ,which returns a score\n",
    "# for each instance ,and then make predictions based on those scores using any threshold\n",
    "# you want:#\n",
    "\n",
    "y_scores=sgd_clf.decision_function([some_digit])\n",
    "y_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2f60eb79c2c256d4a47fab336a9262d674b400d5ee0c4e78852c92653dd4d35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
